{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Binary Classification with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are using the `dl4cv` conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input X contain 100 2D points, and y are their corresponding labels (0 or 1). The goal is to train a model that can classify every point to its correct label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "dataset = np.load('data/2d_pcl_dataset.npz')\n",
    "X, y = dataset['X'], dataset['y']\n",
    "\n",
    "X0 = X[y==0] # 50 2D points have label 0\n",
    "X1 = X[y==1] # 50 2D points have label 1\n",
    "\n",
    "def plot(X0, X1, fit_param=None):\n",
    "    plt.scatter(X0[:,0], X0[:,1], color='red', label=0)\n",
    "    plt.scatter(X1[:,0], X1[:,1], color='blue', label=1)\n",
    "    \n",
    "    plt.xlim([-0.55, 0.55])\n",
    "    plt.ylim([-0.35, 0.25])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "plot(X0, X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression for the point cloud classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting by filling in the `Simple2DDataset` class below. First, in the class constructore `__init__`, you will need to read the right `2d_pcl_dataset.npz` from disk.\n",
    "\n",
    "Second, in the `__getitem__`, you will need to take a single data point and its label based on its index `idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2DDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #########################################################################\n",
    "        # TODO: read data from disk using np.load.\n",
    "        # Data is located in the folder \"data\".\n",
    "        # Save samples and labels to class members self.X and self.y respectively.\n",
    "        # samples should be an Nx2 numpy array. Labels should be Nx1.\n",
    "        #########################################################################\n",
    "        self.X = 0\n",
    "        self.y = 0\n",
    "     \n",
    "    def __len__(self):\n",
    "        # Returns the number of samples in the dataset.\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #########################################################################\n",
    "        # TODO: return the sample and label with index idx\n",
    "        #########################################################################\n",
    "        point = None\n",
    "        label = None\n",
    "        \n",
    "        # Convert to tensor.\n",
    "        return torch.from_numpy(point).float(), \\\n",
    "               torch.from_numpy(label[np.newaxis]).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the complete `Simple2DDataset`, we can create a PyTorch dataloader\n",
    "\n",
    "**NOTE**: if you encounter some unexpected errors in data loading, try setting `NUM_WORKERS = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# create the dataloader\n",
    "dataset = Simple2DDataset()\n",
    "train_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define your first network by filling in the `LinearClassifier` class below.\n",
    "\n",
    "Add a single linear layer `nn.Linear` inside the `nn.Sequential` call. The input is 2D, and the output should be a single value, corresponding to the probability of a given 2D point being part of cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.codename = 'linear'\n",
    "\n",
    "        #########################################################################\n",
    "        # TODO: add a single linear layer with nn.Linear, inside the `nn.Sequential` call.\n",
    "        # Input is 2D.\n",
    "        # Output is a single value.\n",
    "        #########################################################################\n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # Process batch using the defined model.\n",
    "        x = self.model(batch)\n",
    "        # Final sigmoid activation to obtain a probability between 0 and 1.\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you are asked to implement the training loop below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, dataloader, epoch):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    for batch_idx, (point, label) in enumerate(dataloader):\n",
    "        # First we need to zero the gradient, otherwise PyTorch would accumulate them\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #########################################################################\n",
    "        #TODO: \n",
    "        # 1. forward pass of the network to obtain the predictions given the batch\n",
    "        # 2. compute the loss using F.binary_cross_entropy\n",
    "        # 3. backward pass on the loss using loss.backward(), and one step \n",
    "        # of gradient descent (optimization) using optimizer.step()\n",
    "        #########################################################################\n",
    "        loss = 0 \n",
    "\n",
    "        loss_sum += loss\n",
    "    return loss_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now run below to train the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "# create the network.\n",
    "net = LinearClassifier()\n",
    "\n",
    "# create the optimizer.\n",
    "optimizer = Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    loss = train(net, optimizer, train_dataloader, epoch_idx)\n",
    "    print('[Epoch %02d] Loss: %.4f' % (epoch_idx + 1, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot your result below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(-0.5, 0.5, 500)\n",
    "x_plot, y_plot = np.meshgrid(p, p)\n",
    "X_plot = np.stack((x_plot, y_plot), axis=2).reshape(-1, 2)\n",
    "X_plot = torch.from_numpy(X_plot).float()\n",
    "output = net(X_plot)\n",
    "output = output.detach().numpy()\n",
    "output = output.reshape(x_plot.shape[0], x_plot.shape[1])\n",
    "\n",
    "plt.contour(x_plot, y_plot, output, [0.5],\n",
    "                  colors=('k',),\n",
    "                  linewidths=(3,))\n",
    "plot(X0, X1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement your first multi-layer perceptron (MLP) for point cloud classification\n",
    "Now you should notice that your logistic regression model cannot classify the point cloud correctly, and this is as expected :)  \n",
    "Therefore, we now ask you to implement an MLP for the same binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters to be used\n",
    "nInput = 2\n",
    "nOutput = 1\n",
    "nHidden = 16\n",
    "act_fn = nn.ReLU()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, nInput, nOutput, nHidden, act_fn):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the network layers in order.\n",
    "        # Input is 2D (nInput).\n",
    "        # Output is a single value (nOutput).\n",
    "        # Multiple linear layers each followed by a ReLU non-linearity (apart from the last).\n",
    "        #########################################################################\n",
    "        # TODO: add a two-layer MLP, inside the `nn.Sequential` call.\n",
    "        # Input is 2D.\n",
    "        # Output is a single value.\n",
    "\n",
    "        # Hint: unlike logistic regression where you need only one nn.Linear layer, \n",
    "        # here you will have two nn.Linear layers. After the first layer, we \n",
    "        # apply a ReLU activation function. The output is then passed to another \n",
    "        # linear layer. Note that you should use `nHidden` below as the hidden dimension \n",
    "        # of your linear layers.\n",
    "        #########################################################################\n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # Process batch using the defined model.\n",
    "        x = self.model(batch)\n",
    "        # Final sigmoid activation to obtain a probability.\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "# create the network.\n",
    "net = MLP(nInput, nOutput, nHidden, act_fn)\n",
    "\n",
    "# create the optimizer.\n",
    "optimizer = Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    loss = train(net, optimizer, train_dataloader, epoch_idx)\n",
    "    print('[Epoch %02d] Loss: %.4f' % (epoch_idx + 1, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again plot your result. You should see that the decision boundary can clearly separate the point clouds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(-0.5, 0.5, 500)\n",
    "x_plot, y_plot = np.meshgrid(p, p)\n",
    "X_plot = np.stack((x_plot, y_plot), axis=2).reshape(-1, 2)\n",
    "X_plot = torch.from_numpy(X_plot).float()\n",
    "output = net(X_plot)\n",
    "output = output.detach().numpy()\n",
    "output = output.reshape(x_plot.shape[0], x_plot.shape[1])\n",
    "\n",
    "plt.contour(x_plot, y_plot, output, [0.5],\n",
    "                  colors=('k',),\n",
    "                  linewidths=(3,))\n",
    "plot(X0, X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, move forward to `image_classification.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d268b61a0efacafa8645774cb6d0204c9f01d7563ef03f7672146d044e8f345c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
